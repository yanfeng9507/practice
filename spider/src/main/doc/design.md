下载器下载内容:
- 网页
- 图片
- 二进制文件
- js文件

设计爬虫框架要有哪些组成呢？



1. URL管理
2. 网页下载器
3. 爬虫调度器
4. 网页解析器
5. 数据处理器

分别来解释一下每个组成的作用是什么。

URL管理器

爬虫框架要处理很多的URL，我们需要设计一个队列存储所有要处理的URL，这种先进先出的数据结构非常符合这个需求。 将所有要下载的URL存储在待处理队列中，每次下载会取出一个，队列中就会少一个。我们知道有些URL的下载会有反爬虫策略， 所以针对这些请求需要做一些特殊的设置，进而可以对URL进行封装抽出 Request。

网页下载器

在前面的简单例子中可以看出，如果没有网页下载器，用户就要编写网络请求的处理代码，这无疑对每个URL都是相同的动作。 所以在框架设计中我们直接加入它就好了，至于使用什么库来进行下载都是可以的，你可以用 httpclient 也可以用 okhttp， 在本文中我们使用一个超轻量级的网络请求库 oh-my-request (没错，就是在下搞的)。 优秀的框架设计会将这个下载组件置为可替换，提供默认的即可。

爬虫调度器

调度器和我们在开发 web 应用中的控制器是一个类似的概念，它用于在下载器、解析器之间做流转处理。 解析器可以解析到更多的URL发送给调度器，调度器再次的传输给下载器，这样就会让各个组件有条不紊的进行工作。

网页解析器

我们知道当一个页面下载完成后就是一段 HTML 的 DOM 字符串表示，但还需要提取出真正需要的数据， 以前的做法是通过 String 的 API 或者正则表达式的方式在 DOM 中搜寻，这样是很麻烦的，框架 应该提供一种合理、常用、方便的方式来帮助用户完成提取数据这件事儿。常用的手段是通过 xpath 或者 css 选择器从 DOM 中进行提取，而且学习这项技能在几乎所有的爬虫框架中都是适用的。

数据处理器

普通的爬虫程序中是把 网页解析器 和 数据处理器 合在一起的，解析到数据后马上处理。 在一个标准化的爬虫程序中，他们应该是各司其职的，我们先通过解析器将需要的数据解析出来，可能是封装成对象。 然后传递给数据处理器，处理器接收到数据后可能是存储到数据库，也可能通过接口发送给老王。


1. 首先，引擎从调度器中取出一个链接(URL)用于接下来的抓取
2. 引擎把URL封装成一个请求(Request)传给下载器，下载器把资源下载下来，并封装成应答包(Response)
3. 然后，爬虫解析Response
4. 若是解析出实体（Item）,则交给实体管道进行进一步的处理。
5. 若是解析出的是链接（URL）,则把URL交给Scheduler等待抓取


观察者模式实现事件驱动




